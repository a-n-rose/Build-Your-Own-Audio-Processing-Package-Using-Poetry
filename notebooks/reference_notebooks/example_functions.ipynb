{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3968ba-03a0-40d1-9bc0-21b1399b60c9",
   "metadata": {},
   "source": [
    "# Example Functionality\n",
    "\n",
    "Here is a collection of functionality to use as a reference for Part 1 of the workshop.\n",
    "\n",
    "These are not necessarily the best or only way to achieve the desired output. These should serve simply as a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee3d98-960a-4372-9699-2234b2a0632a",
   "metadata": {},
   "source": [
    "## PROGRAMMING CHALLENGE: Get length of audio in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821b34ca-151c-43c6-ab13-09585a6db7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_sec(samples, sampling_rate):\n",
    "    time_sec = len(samples) / sampling_rate\n",
    "    return time_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbef7713-e4ba-4229-9d64-f8df85e31b21",
   "metadata": {},
   "source": [
    "## PROGRAMMING CHALLENGE: Resample Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9f0c58-9af8-4b7f-b052-8eb56b8523d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_audio(samples, sr_old, sr_new):\n",
    "    data = samples.copy()\n",
    "    time_sec = len(data)/sr_old \n",
    "    num_samples = int(time_sec * sr_new)\n",
    "    data = resample(data, num_samples)\n",
    "    return data, sr_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379432ce-1d23-4685-9ab4-64317243f2b1",
   "metadata": {},
   "source": [
    "## PROGRAMMING CHALLENGE: Experiment with the window size\n",
    "\n",
    "Speech: windows range usually from 16 ms to 25 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873fd44-9e20-4f80-96df-8d5aaf4c3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_window_length = 25  # <------ EXPERIMENT WITH THIS VALUE. \n",
    "\n",
    "stft_speech = sp.feats.get_stft(\n",
    "    speech, \n",
    "    sr=speech_sampling_rate, \n",
    "    win_size_ms=fft_window_length,\n",
    "    fft_bins=sr_bird2,\n",
    ")\n",
    "sp.feats.plot(\n",
    "    stft_speech, \n",
    "    feature_type=\"stft\", \n",
    "    title=f\"STFT window length: {fft_window_length} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de8aa4-bc9c-4d9c-a3ec-4337448347bb",
   "metadata": {},
   "source": [
    "Background Noise: windows are longer (length varies; check out some [research papers via Google scholar!](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=noise+classification+machine+learning&btnG=&oq=noise+classification+m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82247143-0ede-4929-a170-6a025bb6a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_window_length = 100  # <------ EXPERIMENT WITH THIS VALUE. \n",
    "\n",
    "stft_speech = sp.feats.get_stft(\n",
    "    speech, \n",
    "    sr=speech_sampling_rate, \n",
    "    win_size_ms=fft_window_length,\n",
    "    fft_bins=sr_bird2,\n",
    ")\n",
    "sp.feats.plot(\n",
    "    stft_speech, \n",
    "    feature_type=\"stft\", \n",
    "    title=f\"STFT window length: {fft_window_length} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371e57e-5926-4e80-a480-23320c2b471b",
   "metadata": {},
   "source": [
    "## PROGRAMMING CHALLENGE: Manipulate the sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3965613a-c2e5-4b96-a5ae-df34e9c3191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_volume(samples, amount):\n",
    "    samps = samples.copy()\n",
    "    samps = samps * amount\n",
    "    return samps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9d9323-bcb5-4d9a-a939-71fef31c3b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_sound(samples):\n",
    "    mirrored_samples = np.concatenate([samples,np.flip(samples[:-1])])\n",
    "    return mirrored_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fab354-7fbb-4c90-ac78-f26215025362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addsounds(samples1, samples2):\n",
    "    if len(samples1) > len(samples2):\n",
    "        return samples1[:len(samples2)] + samples2\n",
    "    return samples1 + samples2[:len(samples1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea77f85-93e9-4a79-af54-585ec826f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_audio(samples, repeat_n_times = 2):\n",
    "    # ensure not to manipulate original data\n",
    "    samps_copy = samples.copy()\n",
    "    orig_shape = samps_copy.shape\n",
    "    # ensure data is mono channel\n",
    "    index_data = np.argmax(orig_shape)\n",
    "    index_channel = np.argmin(orig_shape)\n",
    "    if index_channel != 1 and index_channel != index_data:\n",
    "        raise ValueError(\"Audio should be shape: (num_samples, num_channels).\")\n",
    "    if orig_shape[index_channel] > 1 and index_channel != index_data:\n",
    "        raise ValueError(\"Audio should be mono channel.\")\n",
    "    new_shape = (orig_shape[0] * repeat_n_times,)\n",
    "    samples_repeated = np.empty(new_shape)\n",
    "    index = 0\n",
    "    for i in range(repeat_n_times):\n",
    "        samples_repeated[index:index+len(samps_copy)] = samps_copy\n",
    "        index += len(samps_copy)\n",
    "    return samples_repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192667af-0558-4a5d-b9a7-9bb8a4b479ab",
   "metadata": {},
   "source": [
    "## PROGRAMMING CHALLENGE: Normalize Audio between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561f258-e773-4935-b22d-ef513d0dab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_samples(samples):\n",
    "    \"\"\"Scales the sound to be between -1 and 1.\n",
    "    \"\"\"\n",
    "    ref_max = samples.max()\n",
    "    x = samples.copy()\n",
    "    normed_samples = x / ref_max\n",
    "    return normed_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1008497d-1ffd-4843-b0d1-ea0e11b71d6b",
   "metadata": {},
   "source": [
    "## PROGRAMMING CHALLENGE: Normalize Audio between -1 and 1, uphold original volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed29344-af8b-4641-bbe9-3c851b347ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_samples(samples):\n",
    "    \"\"\"Scales the sound to be between -1 and 1.\n",
    "    \"\"\"\n",
    "    if samples.dtype == \"int16\":\n",
    "        ref_max = 32767 # min: -32768  max: 32767\n",
    "    elif samples.dtype == \"int32\":\n",
    "        ref_max = 2147483647 #  min: -2147483648 max: 2147483647\n",
    "    else: \n",
    "        ref_max = 1 # min: -1  max: 1\n",
    "    x = samples.copy()\n",
    "    return(x / ref_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87516bed-2a15-479c-a5c4-81b0ec2f0a0e",
   "metadata": {},
   "source": [
    "## PROGRAMMING CHALLENGE: Make stereo audio mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20c58e-3faa-4270-9fcd-a566d5eb78e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo2mono(samples):\n",
    "    \"\"\"Sums the channels together to form mono channel data.\n",
    "    \n",
    "    Resources:\n",
    "       https://github.com/microsoft/MS-SNSD/blob/master/audiolib.py \n",
    "    \"\"\"\n",
    "    data = samples.copy()\n",
    "    if np.argmax(data.shape) != 0:\n",
    "        import warnings\n",
    "        msg = \"Sample data expects (num_samples, num_channels). \"+\\\n",
    "            f\"Data supplied has the shape {data.shape}, which looks like \"+\\\n",
    "                \"(num_channels, num_samples). Perhaps check your audio.\"\n",
    "        warnings.warn(msg)\n",
    "    data = data.T\n",
    "    data = data.sum(axis=0)/data.shape[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1fb02-875c-45ee-af86-3c2bd0097a57",
   "metadata": {},
   "source": [
    "## PROGRAMMING CHALLENGE: Visualize features according to research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0d568-fdcd-4252-a8c3-b3fca11a23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_paper = sp.feats.get_mfcc(\n",
    "    samples_speech, \n",
    "    sr=sr_speech, \n",
    "    num_mfcc=40, \n",
    "    win_size_ms=25, \n",
    "    percent_overlap=0.4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
